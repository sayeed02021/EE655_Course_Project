{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec38698b-3224-4743-a496-f7d419b91b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ddbf9c-2c1c-4f79-b6f9-2ee3a98300ea",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003eae70-ee18-418d-a42a-6d1da30dc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamVid_Simple(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.files = glob.glob(path+'/*.pth')\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.load(self.files[index])\n",
    "        return data['img'], data['mask']   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe435f-5420-46d3-a147-0f7e748e4359",
   "metadata": {},
   "source": [
    "# UNET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65afe5aa-9e40-4efc-aee2-7ffe257399b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Source of this is same as the one in Complex_CamVid_Final.ipynb\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "\n",
    "class Simple_UNET(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, features=[64, 128, 256, 512]):\n",
    "        super(Simple_UNET, self).__init__()\n",
    "        self.ups=nn.ModuleList()\n",
    "        self.downs=nn.ModuleList()\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels=feature\n",
    "\n",
    "        \n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                feature*2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "        \n",
    "\n",
    "        self.bottleneck=DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv=nn.Conv2d(features[0], out_channels, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        for down in self.downs:\n",
    "            x=down(x)\n",
    "            skip_connections.append(x)\n",
    "            x=self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1] # reverses order\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x=self.ups[idx](x)\n",
    "            skip_connection=skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x=TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip=torch.cat((skip_connection, x), dim=1)\n",
    "            x=self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9445369-daab-47ff-bf07-8843f2242b11",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8ed7c-3c6f-4b15-a42f-4fb1e24d821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 32\n",
    "batch_size = 8\n",
    "num_epochs = 50\n",
    "lr = 1e-3\n",
    "fpath = 'Dataset/CamVid_RGB'\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Using {device}')\n",
    "\n",
    "model  = Simple_UNET(in_channels = 3, out_channels=num_classes)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "traindataset = CamVid_Simple(path = f'{fpath}/train')\n",
    "\n",
    "trainloader = DataLoader(traindataset, batch_size=batch_size, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = CosineAnnealingLR(optimizer, num_epochs*len(trainloader), eta_min=1e-5)\n",
    "\n",
    "# criterion = Complex_CCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_avg = 0\n",
    "    pbar = tqdm(trainloader)\n",
    "    for batch_idx, (image, mask) in enumerate(pbar):\n",
    "        image, mask = image.to(device), mask.to(device)\n",
    "        output = model(image)\n",
    "        \n",
    "        loss = criterion(output, mask)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        loss_avg+=loss.item()\n",
    "\n",
    "        descrip = {\n",
    "            'Epoch': epoch+1,\n",
    "            'Loss': loss_avg/(batch_idx+1),\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "\n",
    "        pbar.set_postfix(descrip)\n",
    "    pbar.close()\n",
    "    torch.save(model.state_dict(), f'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d7340-ef94-4707-b02b-3d829030d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import JaccardIndex\n",
    "testdataset = CamVid_Simple(path = f'{fpath}/test')\n",
    "num_classes = 32\n",
    "batch_size = 8\n",
    "torch.cuda.empty_cache()\n",
    "metric = JaccardIndex(task='multiclass', num_classes=32)\n",
    "testloader = DataLoader(testdataset, batch_size=batch_size, shuffle=False)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx,(img, target) in enumerate(tqdm(testloader)):\n",
    "        img = img.to(device)\n",
    "        output  = model(img)\n",
    "        output = torch.argmax(output, dim=1)\n",
    "        metric.update(output.cpu(), target)\n",
    "\n",
    "    iou = metric.compute()\n",
    "    print('Jaccard index Score: ', iou)\n",
    "\n",
    "    metric.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
